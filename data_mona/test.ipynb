{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52002\n",
      "489 2467 4181\n",
      "Summarize the following article in 90 words: \n",
      "\n",
      "\n",
      "The internet of things (IoT) is the architecture of the digital world. It connects many devices like smartphones, laptops, and even home appliances, enabling them to communicate with each other. This connectivity enables people to remotely control and monitor the devices, unlocking potential for system scalability, customization, and automation. With IoT, users can easily track, automate, and optimize device performance and energy usage. WASHINGTON (CNN) -- A wide-open presidential race and a willingness by candidates, interest groups, unions and corporations to buy TV time will lead to historic spending for political and issue-advocacy advertising in the 2008 election cycle, an analysis shows. Former Massachusetts Gov. Mitt Romney has spent the most on TV advertising so far among presidential contenders. The cost to try to influence the 2008 election could exceed $3 billion, according to TNS Media Intelligence/Campaign Media Analysis Group, CNN's consultant on political television advertising. This is nearly twice as much than what was spent in 2004 when political and issue-advocacy television advertising rang in at $1.7 billion. In 2006, $2.3 billion was spent on political and issue-advocacy TV commercials. Just about every candidate running for an office from dogcatcher to president is spending the money, said Evan Tracey, CMAG's chief operating officer. The costs to produce a TV commercial are no longer prohibitive for local and state candidates, who are turning more and more to the airwaves to reach voters. See how spending breaks down for this year » . And interest groups have spent $6.2 million on TV ads so far this year for state and local ballot measures. On the national level, the cost of issue-advocacy television ad spending was $270 million in the first nine months of this year. Subjects ranged from the Iraq war to telecommunications reform. Television ads on health care alone total $60 million. CMAG estimates more than $3 million of the $270 million spent to air issue-advocacy ads this year has gone for commercials in states and districts that are likely to have competitive House and Senate races in 2008. Tracey said he thinks this is just the beginning of interest groups \"pivoting from legislative advocacy mode to political mode.\" \"What we expect to see between now and the end of the primaries, and through the general election, is groups will take a more aggressive stance on their advertising and actually target candidates,\" he said. With 17 Democratic and Republican candidates running for president, CMAG predicts that more than $800 million will be spent on TV ads in the battle for the White House. Up to now, the political commercials have been largely focused on the early states of Iowa, New Hampshire and South Carolina. Voters in some of the 20-plus states holding nominating contests on February 5 will start seeing ads in the coming months. 1. Anderson, B. (2012). Climate Change and Human Health: Impacts, Vulnerabilities, and Mitigation. Environmental Health Perspectives, 120(7), 911-19.\n",
      "This paper discusses the link between climate change and public health with an emphasis on impacts, vulnerabilities, and strategies for adaptation and mitigation. It aims to make impacts more tangible, while also highlighting the need to ensure that adaptive mechanisms are in place.\n",
      "\n",
      "2. Ebi, K. L. (2008). Human health in a changing climate. Environmental impact assessment review, 28(3-4), 191-198.\n",
      "This article discusses the potential effects of climate change on human health and how it will vary according to the different variables of the environment. It provides an overview of the main diseases that are likely to be impacted, such as malaria and malnutrition. \n",
      "\n",
      "3. Friel, Sharon & Müller-Nordhorn, Jochen & McMichael, A.J.. (2008). Impacts of climate change on the health of populations: an example from SE Asia. Environmental Impact Assessment Review. 28. 573-586. 10.1016/j.eiar.2008.04.001.\n",
      "This paper provides an example of how climate change can affect human health in Southeast Asia, as well as how local health infrastructure can be adapted and used to minimize its consequences. \n",
      "\n",
      "4. Lemmen, D. S., Warren, F. J., Lacroix, J. A., & Taylor, M. G. (2008). From Impacts to Adaptation: Canada in a Changing Climate 2007. Ottawa, ON: Government of Canada.\n",
      "This report from the Government of Canada examines how climate change can affect human health on a local level in Canada. It focuses on the direct and indirect impacts which can result from changes in temperature, ozone levels, and air pollution.\n",
      "\n",
      "5. Le Six et al. (2009). Health Implications of Climate Change in Canada. CMAJ: Canadian Medical Association Journal,180(11), 1151–1156. https://doi.org/10.1503/cmaj.090005\n",
      "This paper examines how climate change can cause health issues in Canada. It describes how population density, geographic location, and socio-economic status influence the degree of health risk due to climate change. \n",
      "\n",
      "6. Matz, M. & Rumble, C. & Rocklov, J. (2010). Climate change, human health and infectious diseases. International Journal of Public Health. 55. 327-335. 10.1007/s00038-010-0172-7.\n",
      "This article provides an overview of how climate change is likely to affect the spread of infectious diseases, as well as how public health interventions can be implemented to reduce the impact of these diseases.\n",
      "\n",
      "7. Patz, J.A., Campbell-Lendrum, D.H., Holloway, T., Foley, J.A. (2005). Impact of regional climate change on human health. Nature. 438 (7): a30-a33. doi:10.1038/nature04188\n",
      "This paper examines the potential impacts of regional climate change on human health, with a focus on temperature, humidity, and changes in precipitation. It explores how these changes could lead to an increase in the spread of certain diseases.\n",
      "\n",
      "8. Reid, P., Brown, M., & Moser, S. (2007). Human health and climate change: assessing the evidence. Health risks of climate change: an assessment of the evidence. London: Department of Health.\n",
      "This report examines how climate change can affect human health in the UK. It provides a comprehensive overview of the evidence on the impacts of climate change, in order to inform public health interventions.\n",
      "\n",
      "9. Shindell, D., Schmuck, R., & Stone, D. (2013). Avoiding the Unmanageable, Mitigating the Unavoidable: Health Impacts of Climate Change in the United States. International Journal of Environmental Research and Public Health, 10(1), 443-73. doi:10.3390/ijerph10010443\n",
      "This paper examines the health risks posed by climate change in the United States, focusing on air and water pollutant concentrations, vector-borne diseases, vegetation-related allergies and infectious diseases, and floods and heat waves.\n",
      "\n",
      "10. WHO (2007). Impacts of climate change on human health - Setting the World Health Organization agenda in the 21st Century. World Health Organization.\n",
      "This report outlines the potential health impacts of climate change and ways to mitigate them. It provides a review of evidence and recommendations for public health intervention, in order to reduce the health risks posed by climate change.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('alpaca_convo.json', 'r') as f:\n",
    "    data = json.loads(f.read())\n",
    "\n",
    "print(len(data))\n",
    "\n",
    "a = max(data, key=lambda x: len(x['instruction']))\n",
    "b = max(data, key=lambda x: len(x['input']))\n",
    "c = max(data, key=lambda x: len(x['output']))\n",
    "print(len(a['instruction']), len(b['input']), len(c['output']))\n",
    "print(a['instruction'], b['input'], c['output'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/Byron/.cache/huggingface/datasets/HuggingFaceH4___json/HuggingFaceH4--instruction-dataset-2c1af235d4fbca41/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['prompt', 'completion', 'meta'],\n",
      "        num_rows: 327\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset \n",
    "\n",
    "dataset = load_dataset(\"HuggingFaceH4/instruction-dataset\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/Byron/.cache/huggingface/datasets/HuggingFaceH4___json/HuggingFaceH4--instruction-dataset-2c1af235d4fbca41/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Byron\\Documents\\mona_ai\\data_mona\\test.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Byron/Documents/mona_ai/data_mona/test.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39m\u001b[39mHuggingFaceH4/instruction-dataset\u001b[39m\u001b[39m\"\u001b[39m, num_proc\u001b[39m=\u001b[39mnum_proc_load_dataset)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Byron/Documents/mona_ai/data_mona/test.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# make validation dataset \u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Byron/Documents/mona_ai/data_mona/test.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m split_dataset \u001b[39m=\u001b[39m dataset[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mtrain_test_split(test_size\u001b[39m=\u001b[39m\u001b[39m0.0005\u001b[39m, seed\u001b[39m=\u001b[39m\u001b[39m2357\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Byron/Documents/mona_ai/data_mona/test.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m split_dataset[\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m split_dataset\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Byron/Documents/mona_ai/data_mona/test.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# tokenize dataset\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Byron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\dataset_dict.py:57\u001b[0m, in \u001b[0;36mDatasetDict.__getitem__\u001b[1;34m(self, k)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, k) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dataset:\n\u001b[0;32m     56\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(k, (\u001b[39mstr\u001b[39m, NamedSplit)) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 57\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(k)\n\u001b[0;32m     58\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m         available_suggested_splits \u001b[39m=\u001b[39m [\n\u001b[0;32m     60\u001b[0m             split \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m (Split\u001b[39m.\u001b[39mTRAIN, Split\u001b[39m.\u001b[39mTEST, Split\u001b[39m.\u001b[39mVALIDATION) \u001b[39mif\u001b[39;00m split \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[0;32m     61\u001b[0m         ]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'train'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "from datasets import load_dataset \n",
    "\n",
    "num_proc = 8\n",
    "num_proc_load_dataset = num_proc\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    dataset = load_dataset(\"HuggingFaceH4/instruction-dataset\", num_proc=num_proc_load_dataset)\n",
    "\n",
    "    # make validation dataset \n",
    "    split_dataset = dataset[\"train\"].train_test_split(test_size=0.0005, seed=2357, shuffle=True)\n",
    "    split_dataset['val'] = split_dataset.pop('test') \n",
    "\n",
    "    # tokenize dataset\n",
    "    def process(example):\n",
    "        ids = enc.encode_ordinary(example['text']) \n",
    "        ids.append(enc.eot_token) \n",
    "        out = {'ids': ids, 'len': len(ids)}\n",
    "        return out\n",
    "\n",
    "    # tokenize the dataset\n",
    "    tokenized = split_dataset.map(\n",
    "        process,\n",
    "        remove_columns=['text'],\n",
    "        desc=\"tokenizing the splits\",\n",
    "        num_proc=num_proc,\n",
    "    )\n",
    "\n",
    "    # concatenate all the ids in each dataset into one large file we can use for training\n",
    "    for split, dset in tokenized.items():\n",
    "        arr_len = np.sum(dset['len'], dtype=np.uint64)\n",
    "        filename = os.path.join(os.path.dirname(__file__), f'{split}.bin')\n",
    "        dtype = np.uint16 \n",
    "        arr = np.memmap(filename, dtype=dtype, mode='w+', shape=(arr_len,))\n",
    "        total_batches = 1024\n",
    "\n",
    "        idx = 0\n",
    "        for batch_idx in tqdm(range(total_batches), desc=f'writing {filename}'):\n",
    "            batch = dset.shard(num_shards=total_batches, index=batch_idx, contiguous=True).with_format('numpy')\n",
    "            arr_batch = np.concatenate(batch['ids'])\n",
    "            arr[idx : idx + len(arr_batch)] = arr_batch\n",
    "            idx += len(arr_batch)\n",
    "        arr.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/Byron/.cache/huggingface/datasets/byronfong___json/byronfong--mona_convo-6fbe0832534575e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"byronfong/mona_convo\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 9,\n",
       " 'conversation': {'answer': \"Wait... you're suggesting that I'm some kind of computer programme? A machine, with no thoughts and no feelings of my own?\",\n",
       "  'prompt': \"Do you know ur not real\\nI'm not real?... What do you mean? Of course I'm real. I'm sitting right here talking to you, aren't I?\\nlol\"}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[9]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
